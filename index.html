<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Jiarong Xu - Zhejiang University">
    <meta name="author" content="">
    <!--<link rel="shortcut icon" href="img/homeicon.png"> -->

    <title>YIKE LI's Homepage</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="jumbotron.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- <img height="50" src="img/sheep2.jpeg" align="left" hspace="6" style="margin-left:-6p;margin-right:20px"> -->
          <a class="navbar-brand" href="#">Yike Li (李轶珂)</a>
        </div>
        <div class="navbar-collapse collapse">
        <ul class="nav nav-pills pull-right">
          <li class="active"><a href="#">Home</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#publication">Publications</a></li>
          <li><a href="#contact">Contact</a></li>
          <!-- <li><a href="#award">Awards</a></li> -->
        </ul>

          <!--
          <form class="navbar-form navbar-right" role="form">
            <div class="form-group">
              <input type="text" placeholder="Email" class="form-control">
            </div>
            <div class="form-group">
              <input type="password" placeholder="Password" class="form-control">
            </div>
            <button type="submit" class="btn btn-success">Sign in</button>
          </form>
          -->
        </div><!--/.navbar-collapse -->
      </div>
    </div>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container">
        <img height="200" src="img/liyike.jpg" align="left" hspace="6" style="margin-left:-6p;margin-right:20px;">
        <p></p>
        
        <p>I am a final year Ph.D. candidate of Cyberspace Science and Technology in Beijing Jiaotong University, advised by <a href="http://faculty.bjtu.edu.cn/9120/">Prof. Wenjia Niu </a> and <a href="http://faculty.bjtu.edu.cn/9306/"> A/P Endong Tong </a> with Beijing Key Laboratory of Security and Privacy in Intelligent Transportation. I have been visiting Deakin University (working with <a href="https://experts.deakin.edu.au/28663-gang-li/">Prof. Gang Li </a> ) from Feb, 2024 to Aug, 2024. 
        </p>
        
<p>My research interests lie in (1) AI security including robust and privacy-preserving reinforcement learning, and (2) Intelligent Transportation security including adversarial attack and defense in Intelligent Signal System.</p>

<p>For more detailed personal information, please refer to my CV (<a target="_blank" href="works/CV/EN_CV_yikeli.pdf">English version</a>/
  <a target="_blank" href="works/CV/ZH_CV_yikeli.pdf">Chinese version</a>).</p>
        
        <p> <b> Email:</b> yikeli@bjtu.edu.cn </p>

      </div>
    </div>

    <a name="research"></a>

    <div class="container">
        <div class="page-header">
            <h2>Selected Research Work</h2>
        </div>

        <div class="page-header">
            <h4>Robust Reinforcement Learning via Progressive Task Sequence</h4>
        </div>
        <img width="450" src="works/IJCAI.png" align="left" style="margin-left:20px;margin-right:20px;margin-bottom:20px" >

        <p>
        
        Robust reinforcement learning (RL) has been a challenging problem in reliable aspects due to the gap between laboratory simulation and real world. Existing efforts typically address the robust RL problem by solving a maxmin problem, which maximizes the cumulative reward under the worst-possible perturbations. However, the worst-case formulation either leads to overly conservative solutions or unstable training process, which further affects the policy robustness.
         </p>
         <p>
        Motivated by this, we tackle this problem from both formulation definition and algorithm design. First, we formulate the robust RL as a max-expectation optimization problem, where the goal is to an optimal policy under both the worst cases and the non-worst cases. Then, we propose a novel framework DRRL (<a href="https://www.ijcai.org/proceedings/2023/0051.pdf">Li et al IJCAI'23</a>) to solve this max-expectation optimization problem, in which a task generation and sequencing mechanism is introduced to iteratively output new tasks at the appropriate level of difficulty for the current policy. With these progressive tasks, we realize multi-task learning to improve policy robustness and training stability. Extensive experiments demonstrate that DRRL exhibits significant performance on the unmanned CarRacing game and multiple high-dimensional MuJoCo environments.
         </p>
    
    <div class="container">
        <div class="page-header">
            <h4>Curricular Robust Reinforcement Learning</h4>
        </div>
        <img width="450" src="works/TST.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        Existing efforts in robust RL have focused on environmental perturbations. However, one cannot guarantee to train with a positive perturbation as bad ones might bring failures to RL. In this paper (<a href="https://ieeexplore.ieee.org/abstract/document/9837021">Li et al TST'22</a> and <a href="https://www.ndss-symposium.org/ndss-paper/auto-draft-98/">Tian et al AutoSec'21</a>), we first present a generative adversarial network (GAN)-based task generation model to iteratively output perturbations based on the performance of the current policy. We realize curricular learning and finally obtain a robust policy. Extensive experiments in multiple environments demonstrate that our method (a) improves the training stability and (b) is robust to differences in training/test conditions.
        </p>

    </div>

    <div class="container">
        <div class="page-header">
            <h4>Security Analysis for Intelligent Transportation</h4>
        </div>
        <img width="450" src="works/WCMC.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        With the development of emerging intelligent traffic signal (I-SIG) system, congestion-involved security issues are drawing attentions of researchers and developers on the vulnerability introduced by connected vehicle technology, which empowers vehicles to communicate with the surrounding environment such as roadside infrastructure and traffic control units. A congestion attack to the controlled optimization of phases algorithm (COP) of I-SIG is recently revealed. Unfortunately, such analysis still lacks a timely visualized prediction on later congestion when launching an initial attack. 
        </p>
        <p>
        In this paper (<a href="https://doi.org/10.1155/2020/8823300">Li et al, WCMC'20</a>), we argue that traffic image feature-based learning has available knowledge to reflect the relation between attack and caused congestion, and propose a novel analysis framework based on cycle generative adversarial network (CycleGAN). Based on phase order, we first extract four-direction road images of one intersection and perform phase-based composition for generating new sample image of training. We then design a weighted L1 regularization loss that considers both last-vehicle attack and first-vehicle attack, to improve the training of CycleGAN with two generators and two discriminators. Experiments on simulated traffic flow data from VISSIM platform shows the effectiveness of our approach.
        </p>
        
    </div>

	<div class="container">
        <div class="page-header">
            <h4>Multi-agent Reinforcement Learning for Intelligent Transportation</h4>
        </div>
        <img width="450" src="works/TGCN-1.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        Inefficient signal control will not only exaggerate traffic congestion, but also increase the fuel consumption and
exhaust emissions. Thus, signal planning is highly important in green transportation. As the Connected vehicle (CV) technology
has transformed today’s transportation systems by connecting vehicles and the transportation infrastructure through wireless
communication, the CV-based signal control system has seen significant studies recently. Unfortunately, existing signal planning
algorithms in use are developed for the signal-intersection, showing low traffic efficiency in the multi-intersection collaborative
planning due to ignoring the traffic correlation among the neighboring intersections. 
</p>
<p>
In recent work (<a href="https://ieeexplore.ieee.org/document/9743567">Li et al, TGCN'22</a>), we target the USDOT (U.S. Department of Transportation) sponsored CVbased traffic control system, and implement a multi-intersection traffic network. We model the multi-intersection collaborative signal planning problem as a multi-agent reinforcement learning problem, and present an actor-attention-critic algorithm to improve transportation efficiency and energy efficiency in green transportation, as well as resist congestion attack. Experiment results on the multi-intersection traffic network indicates that 1) compared to the baseline, our approach reduces the total delay by as high as 44.24%; 2) our method transports more vehicles passing the intersections meanwhile reduces the total CO2 emissions by 2.40%; 3) under the congestion attack, our approach shows robustness and reduces the total delay by as high as 64.33%.
        </p>
        
    </div>
    </div>
<br>

    <a name="publication"></a>

    <div class="container">
        <div class="page-header">
            <h2>Publication List</h2>
        </div>

        <li style="margin:10px">
        <b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, and Jiqiang Liu.
Robust Reinforcement Learning via Progressive Task Sequence.
In <i> the 32nd International Joint Conference on Artificial Intelligence (IJCAI), 2023</i>.
        </li>
	    
        <li style="margin:10px">
          <b>Yike Li</b>, Jiayin Song, Yunzhe Tian, Endong Tong, Yuling Liu, Guozhu Meng, Yalun Wu, Jianhua Li, Wenjia Niu, and Jiqiang Liu.
        Towards Preventing Imitation Learning Attack via Policy Confusion Defense. 
        Summited to <i>IEEE Transactions on Dependable and Secure Computing (TDSC), 2023 </i> (Under Second Review).
          </li>

        

        <li style="margin:10px">
        <b>Yike Li</b>, Wenjia Niu, Yunzhe Tian, Tong Chen, Zhiqiang Xie, Yalun Wu, Yingxiao Xiang, Endong Tong, Thar Baker, and Jiqiang Liu.
Multiagent Reinforcement Learning-Based Signal Planning for Resisting Congestion Attack in Green Transportation.
In <i>IEEE Transactions on Green Communications and Networking (TGCN), 2022</i>.
        </li>

        <li style="margin:10px">
<b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Yingxiao Xiang, Tong Chen, Yalun Wu, and Jiqiang Liu.
Curricular Robust Reinforcement Learning via GAN-Based Perturbation Through Continuously Scheduled Task Sequence.
In <i>TSINGHUA Science and Technology (TST), 2022</i>.
</li>


        <li style="margin:10px">
<b>Yike Li</b>, Yingxiao Xiang, Endong Tong, Wenjia Niu, Bowei Jia, Long Li, Jiqiang Liu, and Zhen Han.
An Empirical Study on GAN-Based Traffic Congestion Attack Analysis: A Visualized Method.
In <i>Wireless Communications and Mobile Computing (WCMC), 2020</i>.
        </li>

        <li style="margin:10px">
          Yunzhe Tian, <b>Yike Li</b>, Kang Chen, Zhenguo Zhang, Endong Tong, Jiqiang Liu, Fangyun Qin, Zheng Zheng, and Wenjia Niu.
          Towards Label-Efficient Dep Learning-based Aging-rcelated Bug Prediction with Spiking Convolutional Neural Nctworks.
          <i>Submmited to IEEE Transactions on Emerging Topics in Computing (TETC), 2024 (Under Second Review)</i>.
                  </li>

          <li style="margin:10px">
            Jiayin Song, <b>Yike Li</b>, Yunzhe Tian, Xingyu Wu, Qiong Li, Endong Tong, Wenjia Niu, Zhenguo Zhang, and Jiqiang Liu. 
Knowledge-Driven Backdoor Removal in Deep Neural Networks via Reinforcement Learning. 
In <i>the 17th International Conference on Knowledge Science, Engineering and Management (KSEM), 2024</i>.
                    </li>

          <li style="margin:10px">
            Yunzhe Tian, <b>Yike Li</b>, Kang Chen, Endong Tong, Wenjia Niu, Jiqiang Liu, Fangyun Qin, and Zheng Zheng. 
Mitigating Overfitting for Deep Learning-based Aging-related Bug Prediction via Brain-inspired Regularization in Spiking Neural Networks.
In <i>the 16th International Workshop on Software Aging and Rejuvenation (WoSAR), 2023</i>.
                    </li>
                    

        <li style="margin:10px">
Yunzhe Tian, <b>Yike Li</b>, Yingxiao Xiang,
	Wenjia Niu, Endong Tong, and Jiqiang Liu. Curricular Reinforcement Learning for Robust Policy in Unmanned
	CarRacing Game. In <i>NDSS 2021, Workshop
on Automotive and Autonomous Vehicle Security (AutoSec)</i>.

        </li>
        <li style="margin:10px">
相迎宵,<b>李轶珂</b>,刘吉强,王潇瑾,陈彤,童恩栋,牛温佳,韩臻. 面向降频污染攻击的智能交通拥堵态势量化分析. <i>软件学报, 2021</i>.
        </li>
        

        <li style="margin:10px">
Tong Chen, Yingxiao Xiang, <b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Jiqiang Liu, Li Gang
and Qi Alfred Chen. Protecting Reward Function of Reinforcement Learning via Minimal and
Non-catastrophic Adversarial Trajectory. In <i>the 40th International Symposium on Reliable Distributed
Systems (SRDS 2021), 2021</i>.
        </li>

        <li style="margin:10px">
          Zhiqiang Xie, Yingxiao Xiang, <b>Yike Li</b>, Shuang Zhao, Endong Tong, Wenjia Niu, Jiqiang Liu, Jian Wang.
          Security Analysis of Poisoning Attacks Against Multi-agent Reinforcement Learning.  
          In <i>the 21st International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP), 2021</i>.
                  </li>

        <li style="margin:10px">
Yalun Wu, Minglu Song, <b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Bowei Jia, Haixiang
Huang, Qiong Li and Jiqiang Liu. Improving Convolutional Neural Network-based Webshell Detection
through Reinforcement Learning. In <i>the 23rd International Conference on Information and
Communications Security (ICICS 2021), 2021</i>.
        </li>
        <li style="margin:10px">
Xu Gao, Jiqiang Liu, <b>Yike Li</b>, Xiaojin Wang, Yingxiao Xiang, Endong Tong, Wenjia Niu, and Zhen Han.
Queue Length Estimation Based Defence Against Data Poisoning Attack for Traffic Signal Control. In <i>the 10th International Conference on Intelligent Information Processing (IIP 2020), 2020</i>.
        </li>
        
        
        

    </div>
    <a name="activities"></a>
	


    <div class="container">
        <div class="page-header">
            <h2>Academic Experience</h2>
        </div>
        <li style="margin:10px">
        Reviewer of <b>Journal of Information and Knowledge Management (JIKM)</b>.
      </li>
      <li style="margin:10px">
Reviewer of <b>Journal of Intelligent & Fuzzy Systems (JIFS)</b>.
</li>
<li style="margin:10px">
Oral Presentation in <b>CTCIS 2021</b>, Baoding, China.
</li>
<li style="margin:10px">
Oral Presentation in <b>IJCAI 2023</b>, Macao, China.
        </li>

    </div>

    </div>



    <div class="container">
      <div class="page-header">
          <h2>Teaching & Mentoring Experience</h2>
      </div>
      <li style="margin:10px">
        <b>Teaching Assistant</b> (Jun. 2021 - Jul. 2021) </br>
        80S504Q: Information Security Professional Practice and Training  
      </li>
      <li style="margin:10px">
        <b>Teaching Assistant</b> (Feb. 2021 - Apr. 2022) </br>
        M602031B: Situation Awareness of Cyberspace Security  
      </li>
      <li style="margin:10px">
        <b>Guest Lecturer</b> (Feb. 2023 - Aug. 2023) </br>
        M402055B: Artificial Intelligence Security </br>
        Guest Lecture on Reinforcement Learning Security
      </li>
      <li style="margin:10px">
        <b>Research Advising and Mentoring</b>  </br>
        Team leader for the RL group, a subgroup within the <a href="http://jxd308.cn/">THETA Lab</a> led by Prof. Wenjia Niu. </br>
        <ul>
        <li style="margin:5px; margin-left: -30px;">
          Sep. 2020 - Jul. 2022, Yunzhe Tian (BJTU M.S., now  Ph.D. at BJTU)  </br>
   Awarded <b>Outstanding Master Thesis of Beijing Jiaotong University</b>
        </li>
        <li style="margin:5px; margin-left: -30px;">
          Sep. 2021 - Jul. 2024, Shiyao Chen (BJTU M.S., now at CMCC)  </br>
   Awarded <b>Outstanding Master Thesis of Beijing Jiaotong University</b>
        </li>
        <li style="margin:5px; margin-left: -30px;">
          May. 2022 - Jul. 2024, Zhenglong Liu (BJTU B.S., now M.S. at USC)  </br>
   Awarded <b>National-level College Student Innovative Training Program</b>
        </li>
      </ul>
<!-- 
 \vspace*{2mm}

 \textbullet \thickspace Shiyao Chen (BJTU M.S., now at CMCC) \hfill \textit{Sep. 2021 - Jul. 2024} \\
 \quad \thickspace Awarded \textbf{Outstanding Master Thesis of Beijing Jiaotong University} \\

 \vspace*{2mm}
 
\textbullet \thickspace Zhenglong Liu (BJTU B.S., now M.S. at USC) \hfill \textit{May. 2022 - Jul. 2024} \\
 \quad \thickspace Awarded \textbf{National-level College Student Innovative Training Program} \\ -->

      </li>
  </div>

  </div>


    <a name="award"></a>

    <div class="container">
        <div class="page-header">
            <h2>Selected Awards</h2>
        </div>
        
        <li style="margin:10px">
          2022, 2023, 2024,   <b>First-class</b> Doctoral Academic Scholarship of Beijing Jiaotong University
  </li>

  <li style="margin:10px">
    2024, <b>Second Prize</b> of the 34th Huiguang Cup Academic Cultural Festival, Academic Poster Track (Coverage: <a href="https://mp.weixin.qq.com/s?__biz=MzA5MTA2NDAxNA==&mid=2651160713&idx=2&sn=75c9a1a006acacd314913e58422b638c&chksm=8aab1e0193a9e82c5904d721e2b80dde29b8acfdf0157a1b31cd3df69d19b5906294437c84b1&mpshare=1&scene=1&srcid=1013X44eY2DtjLZbz9qu5CfW&sharer_shareinfo=37e01d4c3aaa50096dc78ccc82d008df&sharer_shareinfo_first=37e01d4c3aaa50096dc78ccc82d008df&key=daf9bdc5abc4e8d05dbbe0ac75652b8d4d44c4c8b2921642eb2e002f0f17c1bdfe2dfd107edf158c689ddde594868a39c99cf67222b025bbb8662ff381fd10e3d7f1fe93018b8fba96d22ff6d564eeda773a254bc20c89f274b241372516645177ac61146d75bca273c7e6db26e071bd32261149da87c23cc4cb0ea63002e872&ascene=1&uin=ODY1OTYxMTIx&devicetype=Windows+10&version=62080079&lang=zh_CN&countrycode=CN&exportkey=n_ChQIAhIQCQV2uuCehiuVxhgzgfFxCxLtAQIE97dBBAEAAAAAAMKMA34WTfQAAAAOpnltbLcz9gKNyK89dVj03Ofxn8viqJrlTN6%2BxDAIrB9uL5D%2F3nI0jVvKueLtx8nzMZGVDH45C53dQNf8eAJXjCjGoakAJSJk9yzi3twqKavETl%2Bpym8w%2FU8ba6KckQIpJP%2B4qtvUDrwTZoauoxnEPYZrxBI9Q1JC%2BIptje0LkTkwkiJUl0DtsqXY1HWrQa4ygvFaVC5vg3UySnZcAMqyxInzObc2KKTOONlJo0gjFlCI5blEJp6zcJxPFww45HS9L0wxXphbOLUV675aXcVinMrhpgm%2F3A%3D%3D&acctmode=0&pass_ticket=hfoWzeeLIJtAAWzPqwNdiqjMPrSvKtk5rh9TOXxQaps5%2B5R5P4NmPxVTuJzYrmv6&wx_header=0">34th慧光杯 | 优秀学术海报和创新实践竞赛成果展示 </a>)
</li>

<li style="margin:10px">
  2023, <b>Team First Prize</b> of the DataCon Big Data Security Analysis Competition, AI security Track
</li>

<li style="margin:10px">
  2023, <b>Fourth Place</b> of IEEE Trojan Removal Competition at ICLR 2023.
</li>

        <li style="margin:10px">
        2022,  <b>Team First Prize</b> of The Vulnerability Mining Competition for
    Olympic Winter Games Beijing 2022 (Coverage: <a href="http://scit.bjtu.edu.cn/cms/item/4906.html">计算机学院信安团队参与冬奥卫士演练活动荣获一等奖</a>)
</li>
                <li style="margin:10px">
        2020,  <b>Second Prize</b> of The 17th China Post-Graduate Mathematical Contest in Modeling (Huawei Cup)
</li>
               <li style="margin:10px">
        2017,  <b>Second Prize</b> of The 3th “Internet+” Innovation and Entrepreneurship Competition
</li>
    </div>

    <hr>

    </div>
    <a name="contact"></a>

    <div class="container">
        <div class="page-header">
            <h2>Contact</h2>
        </div>
                <div class="col-xs-12 col-md-8">
                    <ul class="fa-ul">

                        <li>
                            <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
                            <span>
                                <a href="mailto:yikeli@bjtu.edu.cn">yikeli@bjtu.edu.cn</a></span>
                        </li>
                    </ul>
                </div>
    </div>
<!--
    <div style="width: 33%; text-align: center; margin: 0 auto;">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=tebCSlmqux9N9QrcNmOiT0PXzoscPYQd7ftMh0JTTv0&amp;cl=ffffff&amp;w=a"></script>
    </div>
    <hr> -->

    <footer>
        <p style="margin:10px;">Created by <a href=""> Yike Li </a>, using a design from <a href="http://getbootstrap.com/"> bootstrap </a></p>
    </footer>
    </div> <!-- /container

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="dist/js/bootstrap.min.js"></script>
  </body>
</html>
