<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Jiarong Xu - Zhejiang University">
    <meta name="author" content="">
    <!--<link rel="shortcut icon" href="img/homeicon.png"> -->

    <title>YIKE LI's Homepage</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="jumbotron.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!-- <img height="50" src="img/sheep2.jpeg" align="left" hspace="6" style="margin-left:-6p;margin-right:20px"> -->
          <a class="navbar-brand" href="#">Yike Li (李轶珂)</a>
        </div>
        <div class="navbar-collapse collapse">
        <ul class="nav nav-pills pull-right">
          <li class="active"><a href="#">Home</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#publication">Publications</a></li>
          <li><a href="#contact">Contact</a></li>
          <!-- <li><a href="#award">Awards</a></li> -->
        </ul>

          <!--
          <form class="navbar-form navbar-right" role="form">
            <div class="form-group">
              <input type="text" placeholder="Email" class="form-control">
            </div>
            <div class="form-group">
              <input type="password" placeholder="Password" class="form-control">
            </div>
            <button type="submit" class="btn btn-success">Sign in</button>
          </form>
          -->
        </div><!--/.navbar-collapse -->
      </div>
    </div>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container">
        <img height="200" src="img/liyike.jpg" align="left" hspace="6" style="margin-left:-6p;margin-right:20px;">
        <p></p>
        
        <p>I am currently a Ph.D. candidate of Cyberspace Security in Beijing Jiaotong University, advised by <a href="http://faculty.bjtu.edu.cn/9120/">Prof. Wenjia Niu </a> and <a href="http://faculty.bjtu.edu.cn/9306/"> Prof. Endong Tong </a> in Beijing Key Laboratory of Security and Privacy in Intelligent Transportation.
        </p>
        
<p>My research interests lie in (1) AI security including robust and privacy-preserving reinforcement learning, and (2) Intelligent Transportation security including adversarial attack and defense in Intelligent Signal System.</p>
<p>For more detailed personal information, please refer to my <a href="works/CV/CV_yikeli.pdf"> CV</a>.</p>
        
        <p> <b> Email:</b> yikeli@bjtu.edu.cn </p>

      </div>
    </div>

    <a name="research"></a>

    <div class="container">
        <div class="page-header">
            <h2>Selected Research Work</h2>
        </div>

        <div class="page-header">
            <h4>Robust Reinforcement Learning via Progressive Task Sequence</h4>
        </div>
        <img width="450" src="works/IJCAI.png" align="left" style="margin-left:20px;margin-right:20px;margin-bottom:20px" >

        <p>
        
        Robust reinforcement learning (RL) has been a challenging problem in reliable aspects due to the gap between laboratory simulation and real world. Existing efforts typically address the robust RL problem by solving a maxmin problem, which maximizes the cumulative reward under the worst-possible perturbations. However, the worst-case formulation either leads to overly conservative solutions or unstable training process, which further affects the policy robustness.
         </p>
         <p>
        Motivated by this, we tackle this problem from both formulation definition and algorithm design. First, we formulate the robust RL as a max-expectation optimization problem, with the goal of finding an optimal policy under both the worst cases and the non-worst cases. Then, we propose a novel framework DRRL (to appear in IJCAI'23) to solve the max-expectation optimization problem, in which a task generation and sequencing mechanism is introduced to iteratively output new tasks at the appropriate level of difficulty for the current policy. With these progressive tasks, we realize multi-task learning to improve policy robustness and training stability. Extensive experiments demonstrate that DRRL exhibits significant performance on the unmanned CarRacing game and multiple high-dimensional MuJoCo environments.
         </p>
    
    <div class="container">
        <div class="page-header">
            <h4>Curricular Robust Reinforcement Learning</h4>
        </div>
        <img width="450" src="works/TST.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        Existing efforts in robust RL have focused on environmental perturbations. However, one cannot guarantee to train with a positive perturbation as bad ones might bring failures to RL. In this paper (<a href="https://ieeexplore.ieee.org/abstract/document/9837021">Li et al, TST'22</a>), We first present a generative adversarial network (GAN) based task generation model to iteratively output the perturbations at appropriate level of difficulty for the current policy. We realize curricular learning and finally obtain a robust policy. Extensive experiments in multiple environments demonstrate that our method (a) improves the training stability and (b) is robust to differences in training/test conditions.
        </p>

    </div>

    <div class="container">
        <div class="page-header">
            <h4>Security Analysis for Intelligent Transportation</h4>
        </div>
        <img width="450" src="works/WCMC.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        With the development of emerging intelligent traffic signal (I-SIG) system, congestion-involved security issues are drawing attentions of researchers and developers on the vulnerability introduced by connected vehicle technology, which empowers vehicles to communicate with the surrounding environment such as roadside infrastructure and traffic control units. A congestion attack to the controlled optimization of phases algorithm (COP) of I-SIG is recently revealed. Unfortunately, such analysis still lacks a timely visualized prediction on later congestion when launching an initial attack. 
        </p>
        <p>
        In this paper (<a href="https://doi.org/10.1155/2020/8823300">Li et al, WCMC'20</a>), we argue that traffic image feature-based learning has available knowledge to reflect the relation between attack and caused congestion, and propose a novel analysis framework based on cycle generative adversarial network (CycleGAN). Based on phase order, we first extract four-direction road images of one intersection and perform phase-based composition for generating new sample image of training. We then design a weighted L1 regularization loss that considers both last-vehicle attack and first-vehicle attack, to improve the training of CycleGAN with two generators and two discriminators. Experiments on simulated traffic flow data from VISSIM platform shows the effectiveness of our approach.
        </p>
        
    </div>

	<div class="container">
        <div class="page-header">
            <h4>Multi-agent Reinforcement Learning for Intelligent Transportation</h4>
        </div>
        <img width="450" src="works/TGCN-1.png" align="left" style="margin-left:20px;margin-right:20px">
        
        <p>
        Inefficient signal control will not only exaggerate traffic congestion, but also increase the fuel consumption and
exhaust emissions. Thus, signal planning is highly important in green transportation. As the Connected vehicle (CV) technology
has transformed today’s transportation systems by connecting vehicles and the transportation infrastructure through wireless
communication, the CV-based signal control system has seen significant studies recently. Unfortunately, existing signal planning
algorithms in use are developed for the signal-intersection, showing low traffic efficiency in the multi-intersection collaborative
planning due to ignoring the traffic correlation among the neighboring intersections. 
</p>
<p>
In recent work (<a href="https://ieeexplore.ieee.org/document/9743567">Li et al, TGCN'22</a>), we target the USDOT (U.S. Department of Transportation) sponsored CVbased traffic control system, and implement a multi-intersection traffic network. We model the multi-intersection collaborative signal planning problem as a multi-agent reinforcement learning problem, and present an actor-attention-critic algorithm to improve transportation efficiency and energy efficiency in green transportation, as well as resist congestion attack. Experiment results on the multi-intersection traffic network indicates that 1) compared to the baseline, our approach reduces the total delay by as high as 44.24%; 2) our method transports more vehicles passing the intersections meanwhile reduces the total CO2 emissions by 2.40%; 3) under the congestion attack, our approach shows robustness and reduces the total delay by as high as 64.33%.
        </p>
        
    </div>
    </div>
<br>

    <a name="publication"></a>

    <div class="container">
        <div class="page-header">
            <h2>Publication List</h2>
        </div>

        <li style="margin:10px">
        <b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu and Jiqiang Liu.
Robust Reinforcement Learning via Progressive Task Sequence.
In <i>International Joint Conference on Artificial Intelligence (IJCAI), 2023 (To appear)</i>.
        </li>
	    
        <li style="margin:10px">
        <b>Yike Li</b>, Wenjia Niu, Yunzhe Tian, Tong Chen, Zhiqiang Xie, Yalun Wu, Yingxiao Xiang, Endong Tong, Thar Baker, and Jiqiang Liu.
Multiagent Reinforcement Learning-Based Signal Planning for Resisting Congestion Attack in Green Transportation.
In <i>IEEE Transactions on Green Communications and Networking (TGCN), 2022</i>.
        </li>

        <li style="margin:10px">
<b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Yingxiao Xiang, Tong Chen, Yalun Wu, and Jiqiang Liu.
Curricular Robust Reinforcement Learning via GAN-Based Perturbation Through Continuously Scheduled Task Sequence.
In <i>TSINGHUA Science and Technology (TST), 2022</i>.
</li>


        <li style="margin:10px">
<b>Yike Li</b>, Yingxiao Xiang, Endong Tong, Wenjia Niu, Bowei Jia, Long Li, Jiqiang Liu, and Zhen Han.
An Empirical Study on GAN-Based Traffic Congestion Attack Analysis: A Visualized Method.
In <i>Wireless Communications and Mobile Computing (WCMC), 2020</i>.
        </li>
        <li style="margin:10px">
Yunzhe Tian, <b>Yike Li</b>, Yingxiao Xiang,
	Wenjia Niu, Endong Tong, and Jiqiang Liu. Curricular Reinforcement Learning for Robust Policy in Unmanned
	CarRacing Game. In <i>NDSS 2021, Workshop
on Automotive and Autonomous Vehicle Security (AutoSec)</i>.

        </li>
        <li style="margin:10px">
相迎宵,<b>李轶珂</b>,刘吉强,王潇瑾,陈彤,童恩栋,牛温佳,韩臻. 面向降频污染攻击的智能交通拥堵态势量化分析. <i>软件学报, 2021</i>.
        </li>
        

        <li style="margin:10px">
Tong Chen, Yingxiao Xiang,<b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Jiqiang Liu, Li Gang
and Qi Alfred Chen. Protecting Reward Function of Reinforcement Learning via Minimal and
Non-catastrophic Adversarial Trajectory. In <i>the 40th International Symposium on Reliable Distributed
Systems (SRDS 2021), 2021</i>.
        </li>
        <li style="margin:10px">
Yalun Wu, Minglu Song, <b>Yike Li</b>, Yunzhe Tian, Endong Tong, Wenjia Niu, Bowei Jia, Haixiang
Huang, Qiong Li and Jiqiang Liu. Improving Convolutional Neural Network-based Webshell Detection
through Reinforcement Learning. In <i>the 23rd International Conference on Information and
Communications Security (ICICS 2021), 2021</i>.
        </li>
        <li style="margin:10px">
Xu Gao, Jiqiang Liu, <b>Yike Li</b>, Xiaojin Wang, Yingxiao Xiang, Endong Tong, Wenjia Niu, and Zhen Han.
Queue Length Estimation Based Defence Against Data Poisoning Attack for Traffic Signal Control. In <i>the 10th International Conference on Intelligent Information Processing (IIP 2020), 2020</i>.
        </li>
        
        
        

    </div>
    <a name="activities"></a>
	


    <div class="container">
        <div class="page-header">
            <h2>Academic Experience</h2>
        </div>
        <li style="margin:10px">
        Oral Presentation in <b>CTCIS 2021</b>, Baoding, China (remote presentation)
        </li>

    </div>

    </div>
    <a name="award"></a>

    <div class="container">
        <div class="page-header">
            <h2>Selected Awards</h2>
        </div>
        

        <li style="margin:10px">
        2022,  <b>First Prize</b> of The Vulnerability Mining Competition for
    Olympic Winter Games Beijing 2022 (Coverage:<a href="http://scit.bjtu.edu.cn/cms/item/4906.html">计算机学院信安团队参与冬奥卫士演练活动荣获一等奖</a>)
</li>
                <li style="margin:10px">
        2020,  <b>Second Prize</b> of The 17th China Post-Graduate Mathematical Contest in Modeling (Huawei Cup)
</li>
               <li style="margin:10px">
        2017,  <b>Second Prize</b> of The 3th “Internet+” Innovation and Entrepreneurship Competition
</li>
    </div>

    <hr>

    </div>
    <a name="contact"></a>

    <div class="container">
        <div class="page-header">
            <h2>Contact</h2>
        </div>
                <div class="col-xs-12 col-md-8">
                    <ul class="fa-ul">

                        <li>
                            <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
                            <span>
                                <a href="mailto:yikeli@bjtu.edu.cn">yikeli@bjtu.edu.cn</a></span>
                        </li>
                    </ul>
                </div>
    </div>
<!--
    <div style="width: 33%; text-align: center; margin: 0 auto;">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=tebCSlmqux9N9QrcNmOiT0PXzoscPYQd7ftMh0JTTv0&amp;cl=ffffff&amp;w=a"></script>
    </div>
    <hr> -->

    <footer>
        <p style="margin:10px;">Created by <a href=""> Yike Li </a>, using a design from <a href="http://getbootstrap.com/"> bootstrap </a></p>
    </footer>
    </div> <!-- /container

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="dist/js/bootstrap.min.js"></script>
  </body>
</html>
